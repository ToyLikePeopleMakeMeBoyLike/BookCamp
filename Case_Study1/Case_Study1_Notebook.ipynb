{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing Probabilities Using Python\n",
    "## 1.1. Sample Space Analysis: An Equation-Free Approach for Measuring Uncertainty in Outcomes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coin-flip will produce one of 2 measurable outcomes: _Heads_ or _Tails_. By storing outcomes in a Python set, we can create a **sample space** of coin-flips.\n",
    "\n",
    "**Listing 1. 1. Creating a Sample Space of Coin-Flips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.4' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/luis/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "sample_space = {'Heads', 'Tails'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All outcomes within `sample_space` share an identical probability, which is equal to `1 / len(sample_space)`.\n",
    "\n",
    "**Listing 1. 2. Computing the probability of heads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_heads = 1 / len(sample_space)\n",
    "print(f'Probability of choosing heads is {probability_heads}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of choosing `'Heads'` equals 0.5. What is the probability that the coin lands on either heads or on\n",
    "tails? To find rigorous answers, we’ll need to define the\n",
    "concept of an **event**. An event is the subset of those elements within sample_space that\n",
    "satisfy some event condition. An **event condition** is a simple Boolean function whose input\n",
    "is a single sample_space element. \n",
    "\n",
    "**Listing 1. 3. Defining event conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_heads_or_tails(outcome):  return outcome in {'Heads', 'Tails'}\n",
    "def is_neither(outcome): return not is_heads_or_tails(outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, for completeness-sake, lets define event conditions for the two basic events in which the coin satisfies exactly one of our two potential outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Listing 1. 4. Defining additional event conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_heads(outcome): return outcome == 'Heads'\n",
    "def is_tails(outcome): return outcome == 'Tails'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass event conditions into a generalized `get_matching_event` function. The\n",
    "function iterates through `generic_sample_space` and returns the set of outcomes where\n",
    "`event_condition(outcome)` is `True`.\n",
    "\n",
    "**Listing 1. 5. Defining an event detection function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_event(event_condition, generic_sample_space):\n",
    "    return set([outcome for outcome in generic_sample_space \n",
    "                if event_condition(outcome)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets execute `get_matching_event` on our 4 event conditions.\n",
    "\n",
    "**Listing 1. 6. Detecting events using event conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_conditions = [is_heads_or_tails, is_heads, is_tails, is_neither]\n",
    "\n",
    "for event_condition in event_conditions: \n",
    "    print(f\"Event Condition: {event_condition.__name__}\")\n",
    "    event = get_matching_event(event_condition, sample_space)\n",
    "    print(f'Event: {event}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve successfully extracted 4 events from `sample_space`. The probability of each event is equal to `len(event) / len(sample_space)`.\n",
    "\n",
    "**Listing 1. 7. Computing event probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probability(event_condition, generic_sample_space):\n",
    "    event = get_matching_event(event_condition, generic_sample_space)\n",
    "    return len(event) / len(generic_sample_space)\n",
    "\n",
    "for event_condition in event_conditions: \n",
    "    prob = compute_probability(event_condition, sample_space)\n",
    "    name = event_condition.__name__\n",
    "    print(f\"Probability of event arising from '{name}' is {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Analyzing a Biased Coin\n",
    "Suppose a coin is 4 times more likely to land on heads relative to tails. We can represent that coin as a weighted sample space.\n",
    "\n",
    "**Listing 1. 8. Representing a weighted sample space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sample_space = {'Heads': 4, 'Tails': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new sample space is stored within a dictionary. We can redefine sample-space size as the sum of all dictionary weights.\n",
    "\n",
    "**Listing 1. 9. Checking the weighted sample space size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_space_size = sum(weighted_sample_space.values())\n",
    "assert sample_space_size == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can redefine event size in similar manner. Each event is a set of outcomes. These outcomes map to weights. Summing over these weights will yield the event size.\n",
    "\n",
    "**Listing 1. 10. Checking the weighted event size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = get_matching_event(is_heads_or_tails, weighted_sample_space)\n",
    "event_size = sum(weighted_sample_space[outcome] for outcome in event)\n",
    "assert event_size == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our generalized definitions of sample-space size and event size permit us to create a\n",
    "`compute_event_probability function.`\n",
    "\n",
    "**Listing 1. 11. Defining a generalized event probability function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_event_probability(event_condition, generic_sample_space):\n",
    "    event = get_matching_event(event_condition, generic_sample_space)\n",
    "    if type(generic_sample_space) == type(set()):\n",
    "        return len(event) / len(generic_sample_space)\n",
    "    \n",
    "    event_size = sum(generic_sample_space[outcome] \n",
    "                     for outcome in event)\n",
    "    return event_size / sum(generic_sample_space.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now output all the event probabilities for the biased coin without needing to redefine our 4 event condition functions.\n",
    "\n",
    "**Listing 1. 12. Computing weighted event probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_condition in event_conditions: \n",
    "    prob = compute_event_probability(event_condition, weighted_sample_space)\n",
    "    name = event_condition.__name__\n",
    "    print(f\"Probability of event arising from '{name}' is {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Computing Non-Trivial Probabilities\n",
    "### 1.2.1. Problem 1: Analyzing a Family with Four Children\n",
    "Suppose a family has 4 children. What is the probability that exactly 2 of the children are\n",
    "boys? We’ll find solve this by constructing an unweighted sample space where each outcome is a 4-element tuple\n",
    "representing one possible sequence of 4 children.\n",
    "\n",
    "**Listing 1. 13. Computing the sample space of children**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_children = ['Boy', 'Girl']\n",
    "sample_space = set()\n",
    "for child1 in possible_children:\n",
    "    for child2 in possible_children:\n",
    "        for child3 in possible_children:\n",
    "            for child4 in possible_children:\n",
    "                outcome = (child1, child2, child3, child4)\n",
    "                sample_space.add(outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran 4 nested for-loops to explore the sequence of 4 births. This is not an efficient use of\n",
    "code. We can more easily generate our sample space using Python’s build-in `itertools.product` function.\n",
    "\n",
    "**Listing 1. 14. Computing the sample space using `product`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "all_combinations = product(*(4 * [possible_children]))\n",
    "assert set(all_combinations) == sample_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make our code even more efficient by executing `set(product(possible_children, repeat=4))`.\n",
    "\n",
    "**Listing 1. 15. Passing `repeat` into `product`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_space_efficient = set(product(possible_children, repeat=4))\n",
    "assert sample_space == sample_space_efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate the fraction of `sample_space` that is composed of families with 2 boys.\n",
    "\n",
    "**Listing 1. 16. Computing the probability of 2 boys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_two_boys(outcome): return len([child for child in outcome\n",
    "                                      if child == 'Boy']) == 2\n",
    "\n",
    "prob = compute_event_probability(has_two_boys, sample_space)\n",
    "print(f\"Probability of 2 boys is {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Problem 2: Analyzing Multiple Die Rolls\n",
    "Suppose a die is rolled 6 times. What is the probability that these 6 dice-rolls add up to 21? We’ll begin by defining the possible values of any single roll.\n",
    "\n",
    "**Listing 1. 17. Defining all possible rolls of a six-sided die**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_rolls = list(range(1, 7))\n",
    "print(possible_rolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll create the sample space for 6 consecutive rolls.\n",
    "\n",
    "**Listing 1. 18. The sample space for 6 consecutive die rolls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_space = set(product(possible_rolls, repeat=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we’ll define a `has_sum_of_21 event condition` that we’ll subsequently pass into `compute_event_probability`.\n",
    "\n",
    "**Listing 1. 19. Computing the probability of a die-roll sum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_sum_of_21(outcome): return sum(outcome) == 21\n",
    "\n",
    "prob = compute_event_probability(has_sum_of_21, sample_space)\n",
    "print(f\"6 rolls sum to 21 with a probability of {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above analysis can be executed in a single line of code, using Lambda expressions.\n",
    "\n",
    "**Listing 1. 20. Computing the probability using a lambda expression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = compute_event_probability(lambda x: sum(x) == 21, sample_space) \n",
    "assert prob == compute_event_probability(has_sum_of_21, sample_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Problem 3: Computing Die-Roll Probabilities using Weighted Sample Spaces\n",
    "We’ve just computed the likelihood of 6 die-roolls summing to 21. Now, lets recompute\n",
    "that probability using a weighted sample space. By mapping the die-roll sums to their occurrence counts, we will produce a `weighted_sample_space result`.\n",
    "\n",
    "**Listing 1. 21. Mapping die-roll sums to ocurrence counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "weighted_sample_space = defaultdict(int)\n",
    "for outcome in sample_space:\n",
    "    total = sum(outcome)\n",
    "    weighted_sample_space[total] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all weights in `weighted_sample_space` are equal. Some of the weights are much smaller than others. For instance, there is only one way for the dice to sum to 6.\n",
    "\n",
    "**Listing 1. 22. Checking very rare die-roll combinations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert weighted_sample_space[6] == 1\n",
    "assert weighted_sample_space[36] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, the value of `weighted_sample_space[21]` is noticeably higher.\n",
    "\n",
    "**Listing 1. 23. Checking a more common die-roll combination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_combinations = weighted_sample_space[21]\n",
    "print(f\"There are {num_combinations } ways for 6 die rolls to sum to 21\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4332 ways for 6 die-rolls to sum to 21. This is why a sum of 21 is much more probable than a sum of 6.\n",
    "\n",
    "**Listing 1. 24. Exploring different ways of summing to 21**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum([4, 4, 4, 4, 3, 2]) == 21\n",
    "assert sum([4, 4, 4, 5, 3, 1]) == 21 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed count of 4332 is equal to the length of an unweighted event whose die-rolls add up to 21. Hence, there exists a direct link between unweighted and\n",
    "weighted event probability computation.\n",
    "\n",
    "**Listing 1. 25. Comparing weighted events and regular events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = get_matching_event(lambda x: sum(x) == 21, sample_space)\n",
    "assert weighted_sample_space[21] == len(event)\n",
    "assert sum(weighted_sample_space.values()) == len(sample_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final probability of rolling a 21 should remain unchanged.\n",
    "\n",
    "**Listing 1. 26. Computing the weighted event probability of die rolls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = compute_event_probability(lambda x: x == 21, \n",
    "                                 weighted_sample_space)\n",
    "assert prob == compute_event_probability(has_sum_of_21, sample_space)\n",
    "print(f\"6 rolls sum to 21 with a probability of {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the benefit of using a weighted sample space over an unweighted one? Less\n",
    "memory usage!\n",
    "\n",
    "**Listing 1. 27. Comparing weighted to unweighted event space size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Elements in Unweighted Sample Space:')\n",
    "print(len(sample_space))\n",
    "print('Number of Elements in Weighted Sample Space:')\n",
    "print(len(weighted_sample_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Computing Probabilities Over Interval Ranges\n",
    "An **interval** is the set of all the numbers that are sandwiched between 2 boundary cutoffs. Lets define an\n",
    "`is_in_interval` function that checks whether a number falls within a specified interval.\n",
    "\n",
    "**Listing 1. 28. Defining an interval function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_interval(number, minimum, maximum):\n",
    "    return minimum <= number <= maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the `is_in_interval` function, we can compute the probability that an event’s\n",
    "associated value falls within some numeric range. Let’s compute the likelihood\n",
    "that our 6 consecutive die-rolls sum up to a value between 10 and 21.\n",
    "\n",
    "**Listing 1. 29. Computing the probability over an interval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = compute_event_probability(lambda x: is_in_interval(x, 10, 21), \n",
    "                                 weighted_sample_space)\n",
    "print(f\"Probability of interval is {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Evaluating Extremes Using Interval Analysis\n",
    "Suppose we observe 10 flips of an allegedly fair coin, and that coin lands on heads 8 out of 10 times. What is the probability that 10 fair coin-flips produce between 8 and 10 heads? To find out, we'll need the sample space for every possible sequence of 10 flipped coins.\n",
    "\n",
    "**Listing 1. 30. Computing the sample space for 10 coin-flips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coin_sample_space(num_flips=10): \n",
    "    weighted_sample_space = defaultdict(int)\n",
    "    for coin_flips in product(['Heads', 'Tails'], repeat=num_flips):\n",
    "        heads_count = len([outcome for outcome in coin_flips\n",
    "                          if outcome == 'Heads']) \n",
    "        weighted_sample_space[heads_count] += 1\n",
    "\n",
    "    return weighted_sample_space\n",
    "\n",
    "weighted_sample_space = generate_coin_sample_space()\n",
    "assert weighted_sample_space[10] == 1\n",
    "assert weighted_sample_space[9] == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll now compute the probability of observing an interval between 8 and 10 heads.\n",
    "\n",
    "**Listing 1. 31. Computing an extreme head-count probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = compute_event_probability(lambda x: is_in_interval(x, 8, 10),\n",
    "                                 weighted_sample_space)\n",
    "print(f\"Probability of observing more than 7 heads is {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing 8 out of 10 tails is as extreme as observing 8 out of 10 heads. What is the probability of observing more than 7 heads or 7 tails?\n",
    "\n",
    "**Listing 1. 32. Computing an extreme interval probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = compute_event_probability(lambda x: not is_in_interval(x, 3, 7),\n",
    "                                 weighted_sample_space)\n",
    "print(f\"Probability of observing more than 7 heads or 7 tails is {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we flip the coin 10 additional times, and 8 more heads come up. This brings us to 16 heads out of 20 coin-flips. Lets find the probability of 20 fair coin-flips producing more than 15 heads or 15 tails.\n",
    "\n",
    "**Listing 1. 33. Analyzing extreme head-counts for 20 fair coin-flips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sample_space_20_flips = generate_coin_sample_space(num_flips=20)\n",
    "prob = compute_event_probability(lambda x: not is_in_interval(x, 5, 15),\n",
    "                                 weighted_sample_space_20_flips)\n",
    "print(f\"Probability of observing more than 15 heads or 15 tails is {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Plotting Probabilities Using Matplotlib\n",
    "## 2.1. Basic Matplotlib Plots\n",
    "Lets import the Matplotlib plotting library.\n",
    "\n",
    "**Listing 2. 1. Importing Matplotlib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot some linear data using `plt.plot`. \n",
    "\n",
    "**Listing 2. 2. Plotting a linear relationship**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0, 10)\n",
    "y = [2 * value for value in x]\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plotted points have been connected using smooth line segments. We can visualize these points individually using the `plt.scatter` method.\n",
    "\n",
    "**Listing 2. 3. Plotting individual data-points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to emphasize the interval where x begins at 2 and ends at 6. We do this by shading the area under the plotted curve over the specified interval, using the `plt.fill_between` method.\n",
    "\n",
    "**Listing 2. 4. Shading an interval beneath a connected plot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "where = [is_in_interval(value, 2, 6) for value in x]\n",
    "plt.fill_between(x, y, where=where)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets highlight an interval beneath a continuous line while also exposing individual coordinates.\n",
    "\n",
    "**Listing 2. 5. Exposing individual coordinates within a continuous plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, y)\n",
    "plt.fill_between(x, y, where=where)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No data plot is ever truly complete without descriptive x-axis and y-axis labels. Such labels can be set using the `plt.xlabel` and `plt.ylabel` methods.\n",
    "\n",
    "**Listing 2. 6. Adding axes labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.xlabel('Values between zero and ten')\n",
    "plt.ylabel('Twice the values of x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Plotting Coin-Flip Probabilities\n",
    "\n",
    "Our aim is to compare the plotted data from `weighted_sample_space` and `weighted_sample_space_20_flips`. We will begin plotting the elements of `weighted_sample_space`. The x-axis will correspond to `'Head-count'`. The y-axis\n",
    "will correspond to `'Number of coin-flip combinations with x heads'`.\n",
    "\n",
    "**Listing 2. 7. Plotting the coin-flip weighted sample space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_10_flips = list(weighted_sample_space.keys())\n",
    "y_10_flips = [weighted_sample_space[key] for key in x_10_flips]\n",
    "plt.scatter(x_10_flips, y_10_flips)\n",
    "plt.xlabel('Head-count')\n",
    "plt.ylabel('Number of coin-flip combinations with x heads')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the probabilities directly on the y-axis. The probability plot will allow us to replace our lengthy y-axis label with a more concisely stated `'Probability'`.\n",
    "\n",
    "**Listing 2. 8. Plotting the coin-flip probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_space_size = sum(weighted_sample_space.values())\n",
    "prob_x_10_flips = [value / sample_space_size for value in y_10_flips]\n",
    "plt.scatter(x_10_flips, prob_x_10_flips)\n",
    "plt.xlabel('Head-count')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapping between x-values and probabilities is called a **probability distribution**. The total area beneath a\n",
    "probability distribution always equals 1.0.\n",
    "\n",
    "**Listing 2. 9. Confirming that all probabilities sum to 1.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(prob_x_10_flips) == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area beneath the head-count interval of 8 through 10 is equal to the probability of observing 8 heads or more. We can visualize that area using the `plt.fill_between method`. \n",
    "\n",
    "**Listing 2. 10. Shading the interval under a probability curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_10_flips, prob_x_10_flips)\n",
    "plt.scatter(x_10_flips, prob_x_10_flips)\n",
    "where = [is_in_interval(value, 8, 10) for value in x_10_flips]\n",
    "plt.fill_between(x_10_flips, prob_x_10_flips, where=where)\n",
    "plt.xlabel('Head-count')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets also the shade the interval demarcating the probability of observing 8 tails or more.\n",
    "\n",
    "**Listing 2. 11. Shading the interval under the extremes of a probability curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_10_flips, prob_x_10_flips)\n",
    "plt.scatter(x_10_flips, prob_x_10_flips)\n",
    "where = [not is_in_interval(value, 3, 7) for value in x_10_flips]\n",
    "plt.fill_between(x_10_flips, prob_x_10_flips, where=where)\n",
    "plt.xlabel('Head-count')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two symmetrically shaded intervals cover the right and left tail-ends of the coin-flip curve.\n",
    "\n",
    "### 2.2.1. Comparing Multiple Coin-Flip Probability Distributions\n",
    "Lets extend our plot to also encompass the distribution for 20 flipped coins. We’ll plot both distributions on a single figure, though first we must compute the x-axis head-counts and y-axis probabilities for the 20 coin-flip distribution.\n",
    "\n",
    "**Listing 2. 12. Computing probabilities for a 20 coin-flip distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_20_flips = list(weighted_sample_space_20_flips.keys())\n",
    "y_20_flips = [weighted_sample_space_20_flips[key] for key in x_20_flips]\n",
    "sample_space_size = sum(weighted_sample_space_20_flips.values())\n",
    "prob_x_20_flips = [value / sample_space_size for value in y_20_flips]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to visualize the 2 distributions simultaneously.\n",
    "\n",
    "**Listing 2. 13. Plotting two simultaneous distributions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_10_flips, prob_x_10_flips, label='A: 10 coin-flips')\n",
    "plt.scatter(x_10_flips, prob_x_10_flips)\n",
    "plt.plot(x_20_flips, prob_x_20_flips, color='black', linestyle='--',\n",
    "        label='B: 20 coin-flips')\n",
    "plt.scatter(x_20_flips, prob_x_20_flips, color='k', marker='x')\n",
    "plt.xlabel('Head-count')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve visualized our 2 distributions. Next, we’ll proceed to highlight our interval of interest (80% of heads or tails) across each of the 2 plotted curves.\n",
    "\n",
    "**Listing 2. 14. Highlighting intervals beneath two plotted distributions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_10_flips, prob_x_10_flips, label='A: 10 coin-flips')\n",
    "plt.plot(x_20_flips, prob_x_20_flips, color='k', linestyle=':', \n",
    "         label='B: 20 coin-flips')\n",
    "\n",
    "where_10 = [not is_in_interval(value, 3, 7) for value in x_10_flips]\n",
    "plt.fill_between(x_10_flips, prob_x_10_flips, where=where_10)\n",
    "where_20 = [not is_in_interval(value, 5, 15) for value in x_20_flips]\n",
    "plt.fill_between(x_20_flips, prob_x_20_flips, where=where_20)\n",
    "\n",
    "plt.xlabel('Head-Count')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets improve the visualization by aligning the distribution peaks. If we convert the head-counts into frequencies (by\n",
    "dividing by the total coin flips), then both the distribution peaks should align at a frequency of 0.5.\n",
    "\n",
    "**Listing 2. 15. Converting head-counts into frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_10_frequencies = [head_count / 10 for head_count in x_10_flips]\n",
    "x_20_frequencies = [head_count / 20 for head_count in x_20_flips]\n",
    "\n",
    "plt.plot(x_10_frequencies, prob_x_10_flips, label='A: 10 coin-flips')\n",
    "plt.plot(x_20_frequencies, prob_x_20_flips, color='k', linestyle=':', label='B: 20 coin-flips')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Head-Frequency')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 peaks now align. However, the total area beneath each curve no longer equals 1.0. We’ll need to force the aligned curve-areas to equal 1.0 prior to doing interval comparison. The adjusted y-values will no longer be probabilities. They will become **relative likelihoods**.\n",
    "\n",
    "**Listing 2. 16. Computing relative likelihoods of frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_likelihood_10 = [10 * prob for prob in prob_x_10_flips]\n",
    "relative_likelihood_20 = [20 * prob for prob in prob_x_20_flips]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Listing 2. 17. Plotting aligned relative likelihood curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_10_frequencies, relative_likelihood_10, label='A: 10 coin-flips')\n",
    "plt.plot(x_20_frequencies, relative_likelihood_20, color='k',\n",
    "         linestyle=':', label='B: 20 coin-flips')\n",
    "\n",
    "plt.fill_between(x_10_frequencies, relative_likelihood_10, where=where_10)\n",
    "plt.fill_between(x_20_frequencies, relative_likelihood_20, where=where_20)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Head-Frequency')\n",
    "plt.ylabel('Relative Likelihood')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curve A covers a larger area over more extreme head-frequency intervals. Hence, observed recordings of such frequencies are more likely to occur when the coin-flip count is 10 and not 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Running Random Simulations in NumPy\n",
    "## 3.1. Simulating Random Coin-Flips and Die-Rolls Using NumPy\n",
    "Lets import the NumPy numerical computing library.\n",
    "\n",
    "**Listing 3. 1. Importing NumPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can carry out random simulations using the `np.random` module. Calling `np.random.randint(1, 7)` will simulate a single roll of a standard die.\n",
    "\n",
    "**Listing 3. 2. Simulating a randomly rolled die**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "die_roll = np.random.randint(1, 6)\n",
    "assert 1 <= die_roll <= 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll need a way of ensuring that all our random outputs can be reproduced at home. Conveniently, consistency can easily be maintained by calling `np.random.seed(0)`.\n",
    "\n",
    "**Listing 3. 3. Seeding reproducible random die-rolls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "die_rolls = [np.random.randint(1, 7) for _ in range(3)]\n",
    "assert die_rolls == [5, 6, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll now use `np.random.randint(0, 2)` to simulate a single flip of an unbiased\n",
    "coin.\n",
    "\n",
    "**Listing 3. 4. Simulating one fair coin-flip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "coin_flip = np.random.randint(0, 2)\n",
    "print(f\"Coin landed on {'heads' if coin_flip == 1 else 'tails'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll simulate a sequence of 10 coin-flips, and then compute the observed frequency of heads.\n",
    "\n",
    "**Listing 3. 5. Simulating 10 fair coin-flips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def frequency_heads(coin_flip_sequence):\n",
    "    total_heads = len([head for head in coin_flip_sequence if head == 1])\n",
    "    return total_heads / len(coin_flip_sequence)\n",
    "\n",
    "coin_flips = [np.random.randint(0, 2) for _ in range(10)]\n",
    "freq_heads = frequency_heads(coin_flips)\n",
    "print(f\"Frequency of Heads is {freq_heads}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what happens when we flip the coin 1000 times. After each flip, we will record the total frequency of heads observed in the sequence. Once the coin-flips are completed, we will plot the results.\n",
    "\n",
    "**Listing 3. 6. Plotting simulated fair coin-flip frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "coin_flips = []\n",
    "frequencies = []\n",
    "for _ in range(1000):\n",
    "    coin_flips.append(np.random.randint(0, 2))\n",
    "    frequencies.append(frequency_heads(coin_flips))\n",
    "\n",
    "plt.plot(list(range(1000)), frequencies)\n",
    "plt.axhline(0.5, color='k')\n",
    "plt.xlabel('Number of Coin Flips')\n",
    "plt.ylabel('Head-Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of heads slowly converges to 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 3.1.1. Analyzing Biased Coin-Flips\n",
    "Lets simulate a coin that falls on heads 70% of the time? We'll generate that biased output by calling `np.random.binomial(1, .7)`.\n",
    "\n",
    "**Listing 3. 7. Simulating biased coin-flips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "print(\"Lets flip the biased coin once.\")\n",
    "coin_flip = np.random.binomial(1, 0.7)\n",
    "print(f\"Biased coin landed on {'heads' if coin_flip == 1 else 'tails'}.\")\n",
    "\n",
    "print(\"\\nLets flip the biased coin 10 times.\")\n",
    "number_coin_flips = 10\n",
    "head_count = np.random.binomial(number_coin_flips, .7)\n",
    "print((f\"{head_count} heads were observed out of \" \n",
    "       f\"{number_coin_flips} biased coin flips\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets generate a sequence of 1000 biased coin-flips. We’ll then check if the frequency converges to 0.7.\n",
    "\n",
    "**Listing 3. 8. Computing coin-flip frequency convergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "head_count = np.random.binomial(1000, .7)\n",
    "frequency = head_count / 1000\n",
    "print(f\"Frequency of Heads is {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency is .03 units smaller than the true probability of heads. Suppose we recompute the frequency of 1000 coin-flips five more times. Will any of the frequencies be equal to 0.7? \n",
    "\n",
    "**Listing 3. 9. Re-computing coin-flip frequency convergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "assert np.random.binomial(1000, 0.7) / 1000 == 0.697\n",
    "for i in range(1, 6):\n",
    "    head_count = np.random.binomial(1000, .7)\n",
    "    frequency = head_count / 1000\n",
    "    print(f\"Frequency at iteration {i} is {frequency}\")\n",
    "    if frequency == 0.7:\n",
    "        print(\"Frequency equals the probability!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one out the 5 iterations produced a measurement that equaled the real probability. The observed frequency appears to fluctuate over every sampling of 1000 coin-flips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Computing Confidence Intervals Using Histograms and NumPy Arrays\n",
    "We’ve previously sampled our coin over 5 iterations of 1000 coin-flips each. The sampling produced some fluctuations in the frequency. Lets explore these fluctuations by increasing our frequency count from 5 to 500.\n",
    "\n",
    "**Listing 3. 10. Computing frequencies with 500 flips-per-sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "head_count_list = [np.random.binomial(1000, 0.7) for _ in range(500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can more efficiently sample over 500 iterations by running `np.random.binomial(coin_flip_count, 0.7, size=500)`. \n",
    "\n",
    "**Listing 3. 11. Optimizing the coin-flip frequency computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "head_count_array = np.random.binomial(1000, 0.7, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is not a Python list, but a NumPy array data-structure. The actual numeric quantities stored\n",
    "with both `head_count_array` and `head_count_list` remain the same.\n",
    "\n",
    "**Listing 3. 12. Converting a NumPy array to a Python list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert head_count_array.tolist() == head_count_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert our Python list into a value-equivalent NumPy array by calling np.array(head_count_list).\n",
    "\n",
    "**Listing 3. 13. Converting a Python list to a NumPy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = np.array(head_count_list)\n",
    "assert np.array_equal(new_array, head_count_array) == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing a NumPy array by some number will automatically divide all array elements by that number. Thus, executing `head_count_array / 1000` will automatically transform our head-counts into frequencies.\n",
    "\n",
    "**Listing 3. 14. Computing frequencies using NumPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_array = head_count_array / 1000\n",
    "assert frequency_array.tolist() == [head_count / 1000\n",
    "                                    for head_count in head_count_list]\n",
    "assert frequency_array.tolist() == list(map(lambda x: x / 1000, \n",
    "                                        head_count_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore the contents of `frequency_array` in greater detail. We’ll start by printing the first 20 sampled frequencies within the array.\n",
    "\n",
    "**Listing 3. 15. Printing a NumPy frequency array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frequency_array[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets extract the minimum and maximum frequencies values by calling the `frequency_array.min()` and\n",
    "`frequency_array.max()` array methods.\n",
    "\n",
    "**Listing 3. 16. Finding the largest and smallest frequency values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = frequency_array.min()\n",
    "max_freq = frequency_array.max()\n",
    "print(f\"Minimum frequency observed: {min_freq}\")\n",
    "print(f\"Maximum frequency observed: {max_freq}\")\n",
    "print(f\"Difference across frequency range: {max_freq - min_freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhere between the frequency range of 0.656 to 0.733 lies the true probability of\n",
    "heads. How can we rationally narrow the frequency range? Plotting the data could help.\n",
    "\n",
    "**Listing 3. 17. Plotting measured frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_counts = defaultdict(int)\n",
    "for frequency in frequency_array:\n",
    "    frequency_counts[frequency] += 1\n",
    "\n",
    "frequencies = list(frequency_counts.keys())\n",
    "counts = [frequency_counts[freq] for freq in frequencies]\n",
    "plt.scatter(frequencies, counts)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plot is somewhat flawed, since values that are very close get counted separately. Perhaps instead of treating these values as individual points, we should group such proximate frequencies together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Binning Similar Points in Histogram Plots\n",
    "\n",
    "We’ll sub-divide our frequency range into N equally spaced bins, and then place all frequency values into one of those bins.  Afterwards, we’ll count the total values in each bin, and visualize the counts using a plot. This type of **histogram** plot can be carried out using the `plt.hist` method.\n",
    "\n",
    "**Listing 3. 18. Plotting a frequency histogram using plt.hist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(frequency_array, bins='auto', edgecolor='black')\n",
    "plt.xlabel('Binned Frequency')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total count of bins within the plot is not yet known. However, we can obtain that information using `counts`, which is a NumPy array returned by `plt.hist`.\n",
    "\n",
    "**Listing 3. 19. Counting bins in a plotted histogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, _, _ = plt.hist(frequency_array, bins='auto', \n",
    "                        edgecolor='black')\n",
    "\n",
    "print(f\"Number of Bins: {counts.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How wide is each bin? To find out, we'll leverage the `bin_edges` array, which is the second variable\n",
    "returned by `plt.hist`.\n",
    "\n",
    "**Listing 3. 20. Finding the width of bins within a histogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bin_edges, _ = plt.hist(frequency_array, bins='auto',\n",
    "                                edgecolor='black')\n",
    "\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "assert bin_width == (max_freq - min_freq) / counts.size\n",
    "print(f\"Bin width: {bin_width}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bin_edges` array can be used in tandem with `counts` to output the element-count and\n",
    "coverage-range for any specified bin. \n",
    "\n",
    "**Listing 3. 21. Getting a bin’s frequency and size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_bin_coverage(i):\n",
    "    count = int(counts[i])\n",
    "    range_start, range_end = bin_edges[i], bin_edges[i+1]\n",
    "    range_string = f\"{range_start} - {range_end}\"\n",
    "    print((f\"The bin for frequency range {range_string} contains \" \n",
    "           f\"{count} element{'' if count == 1 else 's'}\"))\n",
    "    \n",
    "output_bin_coverage(0)\n",
    "output_bin_coverage(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s compute the count and frequency range for the highest peak within our histogram. Conveniently, NumPy arrays have a built-in `argmax` method, which returns the index of the maximum value within a given array.\n",
    "\n",
    "**Listing 3. 22. Finding the index of an array’s maximum value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert counts[counts.argmax()] == counts.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, calling `output_bin_coverage(counts.argmax())` should provide us with the output we’ve requested.\n",
    "\n",
    "**Listing 3. 23. Using `argmax` to return a histogram’s peak**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_bin_coverage(counts.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Deriving Probabilities from Histograms\n",
    "We wish to calculate the likelihood that a randomly measured frequency falls within 0.694 - 0.699. The likelihood of an interval equals its area under a curve, but only when the total plotted area sums up to 1.0. We thus must modify our histogram by transforming the counts into relative likelihoods.\n",
    "\n",
    "**Listing 3. 24. Plotting a histogram’s relative likelihoods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods, bin_edges, _ = plt.hist(frequency_array, bins='auto', edgecolor='black', density=True)\n",
    "plt.xlabel('Binned Frequency')\n",
    "plt.ylabel('Relative Likelihood')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total area beneath our histogram now sums to 1.0.\n",
    "\n",
    "**Listing 3. 25. Computing the total area under a histogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert likelihoods.sum() * bin_width == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the area beneath the histogram’s peak is now a probability. We can compute that probability by calculating the area of the bin positioned at `likelihoods.argmax()`.\n",
    "\n",
    "**Listing 3. 26. Computing the probability of the peak frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = likelihoods.argmax()\n",
    "area = likelihoods[index] * bin_width\n",
    "range_start, range_end = bin_edges[index], bin_edges[index+1]\n",
    "range_string = f\"{range_start} - {range_end}\"\n",
    "print(f\"Sampled frequency falls within interval {range_string} with probability {area}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability is low, but we can raise it by expanding our interval range beyond one bin. We’ll stretch the range to cover neighboring bins at `indices likelihoods.argmax() - 1` and `likelihoods.argmax() + 1`.\n",
    "\n",
    "**Listing 3. 27. Raising the probability of a frequency range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_index = likelihoods.argmax()\n",
    "start_index, end_index = (peak_index - 1, peak_index + 2)\n",
    "area = likelihoods[start_index: end_index + 1].sum() * bin_width\n",
    "range_start, range_end = bin_edges[start_index], bin_edges[end_index]\n",
    "range_string = f\"{range_start} - {range_end}\"\n",
    "print(f\"Sampled frequency falls within interval {range_string} with probability {area}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three bins represent what statisticians call a 46.4% **confidence interval**. Ideally, we’d prefer a confidence interval of 95% or more. We’ll reach that confidence interval by iteratively expanding our left-most bin and right-most bin until the interval area stretches past 0.95.\n",
    "\n",
    "**Listing 3. 28. Computing a high confidence interval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_high_confidence_interval(likelihoods, bin_width):\n",
    "    peak_index = likelihoods.argmax()\n",
    "    area = likelihoods[peak_index] * bin_width\n",
    "    start_index, end_index = peak_index, peak_index + 1\n",
    "    while area < 0.95:\n",
    "        if start_index > 0:\n",
    "            start_index -= 1\n",
    "        if end_index < likelihoods.size - 1:\n",
    "            end_index += 1\n",
    "\n",
    "        area = likelihoods[start_index: end_index + 1].sum() * bin_width\n",
    "    \n",
    "    range_start, range_end = bin_edges[start_index], bin_edges[end_index]\n",
    "    range_string = f\"{range_start:.6f} - {range_end:.6f}\"\n",
    "    print((f\"The frequency range {range_string} represents a \"\n",
    "           f\"{100 * area:.2f}% confidence interval\"))\n",
    "    return start_index, end_index\n",
    "\n",
    "compute_high_confidence_interval(likelihoods, bin_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our analysis, we’re fairly confident that the true probability lies somewhere between 0.670 and 0.723."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Shrinking the Range of a High Confidence Interval\n",
    "How can we taper down our range while still maintaining a 95% confidence interval? Perhaps we should try elevating the frequency count from 500 to 100,000.\n",
    "\n",
    "**Listing 3. 29. Sampling 100,000 frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "head_count_array = np.random.binomial(1000, 0.7, 100000)\n",
    "frequency_array = head_count_array / 1000\n",
    "assert frequency_array.size == 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will re-compute the histogram on the updated `frequency_array`. Afterwards, we’ll visualize that histogram while also searching for a high confidence interval. Lets incorporate the confidence interval into our visualization by coloring the histogram bars within its range.\n",
    "\n",
    "**Listing 3. 30. Coloring histogram bars over an interval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods, bin_edges, patches = plt.hist(frequency_array, bins='auto', \n",
    "                                           edgecolor='black', density=True)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "start_index, end_index = compute_high_confidence_interval(likelihoods, \n",
    "                                                          bin_width)\n",
    "\n",
    "for i in range(start_index, end_index):\n",
    "     patches[i].set_facecolor('yellow')\n",
    "plt.xlabel('Binned Frequency')\n",
    "plt.ylabel('Relative Likelihood')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new frequency range is nearly identical to the one we saw before. Raising the sampling size\n",
    "from 500 to 100,000 appears to have done little to reduce the range. Perhaps we should’ve also raised the number of coin-flips per frequency-sample.  Lets increase this value 50-fold to 50,000 coin-flips per sampled frequency.\n",
    "\n",
    "**Listing 3. 31. Sampling 5 billion flipped coins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "head_count_array = np.random.binomial(50000, 0.7, 100000)\n",
    "frequency_array = head_count_array / 50000\n",
    "\n",
    "likelihoods, bin_edges, patches = plt.hist(frequency_array, bins='auto',\n",
    "                                           edgecolor='black', density=True)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "start_index, end_index = compute_high_confidence_interval(likelihoods, bin_width)\n",
    "\n",
    "for i in range(start_index, end_index):\n",
    "     patches[i].set_facecolor('yellow')\n",
    "plt.xlabel('Binned Frequency')\n",
    "plt.ylabel('Relative Likelihood')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new 95.06% confidence interval covers a frequency range of roughly 0.695 - 0.703. We are thus exceedingly confident that our true probability is approximately 0.70."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. Computing Histograms in NumPy\n",
    "Calling the `plt.hist` method will automatically generate a histogram plot. Can we obtain the histogram likelihoods and bin-edges without creating a plot? Yes; we simply need to call `np.histogram.`\n",
    "\n",
    "**Listing 3. 32. Computing a histogram using `np.histogram`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "likelihoods, bin_edges = np.histogram(frequency_array, bins='auto',\n",
    "                                      density=True)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "compute_high_confidence_interval(likelihoods, bin_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Leveraging Confidence Intervals to Analyze a Biased Deck of Cards\n",
    "Lets model a deck containing a hidden quantity of red cards. The total size of that deck is 52. The number of red cards in the deck is some unknown integer between zero and 52. We'll generate that integer using the `np.random.randint` method.\n",
    "\n",
    "**Listing 3. 33. Generating a random red card count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "total_cards = 52\n",
    "red_card_count = np.random.randint(0, total_cards + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets assign a value to `black_card_count`.\n",
    "\n",
    "**Listing 3. 34. Generating a black card count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_card_count = total_cards - red_card_count\n",
    "assert black_card_count != red_card_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability that the first card will be red? Well, our card deck is biased, and the outcomes are not equally likely. Thus, a weighted sample space dictionary is required to compute the probability.\n",
    "\n",
    "**Listing 3. 35. Computing card probabilities using a sample space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sample_space = {'red_card': red_card_count,\n",
    "                         'black_card': black_card_count}\n",
    "prob_red = compute_event_probability(lambda x: x == 'red_card',\n",
    "                                     weighted_sample_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can easily show that the probability of drawing a red card is equal to `red_card_count` divided by `total_cards`.\n",
    "\n",
    "**Listing 3. 36. Computing card probabilities using division**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert prob_red == red_card_count / total_cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll utilize `prob_red` to model a flipped-over first card using the Binomial distribution.\n",
    "\n",
    "**Listing 3. 37. Simulating a random card**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "color = 'red' if np.random.binomial(1, prob_red) else 'black'\n",
    "print(f\"The first card in the shuffled deck is {color}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll proceed to shuffle the deck 10 times, and flip over the first card after each shuffle.\n",
    "\n",
    "**Listing 3. 38. Simulating 10 random cards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "red_count = np.random.binomial(10, prob_red)\n",
    "print(f\"In {red_count} of out 10 shuffles, a red card came up first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now shuffle now shuffle the deck 50,000 times. Afterwards, lets compute the frequency and then re-do the shuffling procedure another 100,000 times. We use the resulting frequencies to compute a 95% confidence interval for flipping over a red card.\n",
    "\n",
    "**Listing 3. 39. Computing card-probability confidence intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "red_card_count_array = np.random.binomial(50000, prob_red, 100000) \n",
    "frequency_array = red_card_count_array / 50000\n",
    "\n",
    "likelihoods, bin_edges = np.histogram(frequency_array, bins='auto', \n",
    "                                      density=True)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "start_index, end_index = compute_high_confidence_interval(likelihoods, bin_width) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are highly confident that red_card_count lies between `0.842865 * total_cards` and `0.849139 *\n",
    "total_cards`. Let’s compute the likely range of `red_card_count`.\n",
    "\n",
    "**Listing 3. 40. Estimating the red card count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_start = round(0.842865 * total_cards)\n",
    "range_end = round(0.849139 * total_cards)\n",
    "print(f\"The number of red cards in the deck is between {range_start} and {range_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very confident that there are 44 red cards in the deck. Lets check if our solution is\n",
    "correct.\n",
    "\n",
    "**Listing 3. 41. Validating the red card count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if red_card_count == 44:\n",
    "    print('We are correct! There are 44 red cards in the deck')\n",
    "else:\n",
    "    print('Oops! Our sampling estimation was wrong.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Using Permutations to Shuffle Cards\n",
    "Card-shuffling requires us to randomly re-order the elements of a card-deck. That random\n",
    "re-ordering can be carried out using the `np.random.shuffle` method.\n",
    "\n",
    "**Listing 3. 42. Shuffling a 4-card deck**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "card_deck = [1, 1, 0, 0]\n",
    "np.random.shuffle(card_deck)\n",
    "print(card_deck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we prefer to carry out the shuffle while retaining a copy of the original unshuffled deck, we can do so using\n",
    "`np.random.permutation`.\n",
    "\n",
    "**Listing 3. 43. Returning a copy of the shuffled deck**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "unshuffled_deck = [1, 1, 0, 0]\n",
    "shuffled_deck = np.random.permutation(unshuffled_deck)\n",
    "assert unshuffled_deck == [1, 1, 0, 0]\n",
    "print(shuffled_deck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random ordering of elements returned by `np.random.permutation` is mathematically called a **permutation**. Calling `itertools.permutations(unshuffled_deck)` will return an iterable over every possible permutation of the deck.\n",
    "\n",
    "**Listing 3. 44. Iterating over card permutations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "for permutation in list(itertools.permutations(unshuffled_deck))[:3]:\n",
    "    print(permutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 2 generated permutations are identical to each other, because identical zeros were swapped by the `permutation` function. We can confirm the swap actually took place by examining the first\n",
    "three permutations of `[0, 1, 2, 3]`.\n",
    "\n",
    "**Listing 3. 45. Monitoring permutation swaps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for permutation in list(itertools.permutations([0, 1, 2, 3]))[:3]:\n",
    "    print(permutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain permutations of the 4-card deck occur more than once.  Let’s store these permutation counts within a `weighted_sample_space` dictionary.\n",
    "\n",
    "**Listing 3. 46. Computing permutation counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sample_space = defaultdict(int)\n",
    "for permutation in itertools.permutations(unshuffled_deck):\n",
    "    weighted_sample_space[permutation] += 1\n",
    "\n",
    "for permutation, count in weighted_sample_space.items():\n",
    "    print(f\"Permutation {permutation} occurs {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the permutations occur with equal frequency. Consequently, an unweighted sample space should be sufficient to compute permutation probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_space = set(itertools.permutations(unshuffled_deck)) \n",
    "event_condition = lambda x: list(x) == unshuffled_deck \n",
    "prob = compute_event_probability(event_condition, sample_space) \n",
    "assert prob == 1 / len(sample_space)\n",
    "print(f\"Probability that a shuffle does not alter the deck is {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute probabilities directly from the unweighted sample. Unfortunately, creating this sample space is not feasible for a deck of 52 cards. However, such a sample space could easily be computed for smaller deck of size 10.\n",
    "\n",
    "**Listing 3. 48. Computing a 10-card sample space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_cards = 5 * [1]\n",
    "black_cards = 5 * [0]\n",
    "unshuffled_deck = red_cards + black_cards\n",
    "sample_space = set(itertools.permutations(unshuffled_deck))\n",
    "print(f\"Sample space for a 10-card deck contains {len(sample_space)} elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Case Study 1 Solution\n",
    "##  4.1. Overview\n",
    "Our aim is to play a card-game in which the cards are iteratively flipped until we tell the\n",
    "dealer to stop. Afterwards, one additional card is flipped. If that card is red, we win a dollar.\n",
    "Otherwise, we lose a dollar.\n",
    "\n",
    "## 4.2. Predicting Red Cards within a Shuffled Deck\n",
    "We’ll start by creating a deck holding 26 red cards and 26 black cards. Black cards are\n",
    "represented by zeroes and red cards are represented by ones.\n",
    "\n",
    "**Listing 4. 1. Modeling a 52-card deck**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_cards = 26 * [1]\n",
    "black_cards = 26 * [0]\n",
    "unshuffled_deck = red_cards + black_cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll proceed to shuffle the deck.\n",
    "\n",
    "**Listing 4. 2. Shuffling a 52-card deck**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "shuffled_deck = np.random.permutation(unshuffled_deck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll iteratively flip over the cards within the deck, stopping when the the number of red cards remaining in the deck is greater than the number of black cards remaining in the deck.\n",
    "\n",
    "**Listing 4. 3. Coding a card-game strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_red_cards = 26\n",
    "for i, card in enumerate(shuffled_deck[:-1]):\n",
    "    remaining_red_cards -= card\n",
    "    remaining_total_cards = 52 - i - 1\n",
    "    if remaining_red_cards / remaining_total_cards > 0.5:\n",
    "        break\n",
    "\n",
    "print(f\"Stopping the game at index {i}.\")\n",
    "final_card = shuffled_deck[i + 1]\n",
    "color = 'red' if final_card else 0\n",
    "print(f\"The next card in the deck is {'red' if final_card else 'black'}.\")\n",
    "print(f\"We have {'won' if final_card else 'lost'}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy yielded a win on our very first try. Lets generalize this strategy to halt when the\n",
    "fraction of remaining red cards is greater than an inputted `min_red_fraction` parameter.\n",
    "\n",
    "**Listing 4. 4. Generalizing the card-game strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cards = 52\n",
    "total_red_cards = 26\n",
    "def execute_strategy(min_fraction_red=0.5, shuffled_deck=None,\n",
    "                     return_index=False):\n",
    "    if shuffled_deck is None:\n",
    "        shuffled_deck = np.random.permutation(unshuffled_deck) \n",
    "        \n",
    "    remaining_red_cards = total_red_cards\n",
    "\n",
    "    for i, card in enumerate(shuffled_deck[:-1]):\n",
    "        remaining_red_cards -= card\n",
    "        fraction_red_cards = remaining_red_cards / (total_cards - i - 1)\n",
    "        if fraction_red_cards > min_fraction_red:\n",
    "            break\n",
    "            \n",
    "    return (i+1, shuffled_deck[i+1]) if return_index else shuffled_deck[i+1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Estimating the Probability of Strategy Success\n",
    "Lets apply our basic strategy to a series of 1000 random shuffles.\n",
    "\n",
    "**Listing 4. 5. Running strategy over 1000 shuffles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "observations = np.array([execute_strategy() for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total fraction of ones in observations corresponds to the observed fraction of red cards, and therefore to the fraction of wins. We can compute this fraction by calling `observations.mean()`.\n",
    "\n",
    "**Listing 4. 6. Computing the frequency of wins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_wins = observations.sum() / 1000\n",
    "assert frequency_wins == observations.mean()\n",
    "print(f\"The frequency of wins is {frequency_wins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve won 51.1 percent of total games! Our strategy appears to be working. 524 wins and 76 losses will net us a total profit of $22.\n",
    "\n",
    "**Listing 4. 7. Computing total profit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollars_won = frequency_wins * 1000\n",
    "dollars_lost = (1 - frequency_wins) * 1000\n",
    "total_profit = dollars_won - dollars_lost\n",
    "print(f\"Total profit is ${total_profit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy worked well for a sample size of 1000 shuffles. We’ll now plot the strategy’s\n",
    "win-frequency convergence over a series of sample sizes ranging from 1 to 10,000.\n",
    "\n",
    "**Listing 4. 8. Plotting simulated frequencies of wins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def repeat_game(number_repeats):\n",
    "    observations = np.array([execute_strategy()\n",
    "                             for _ in range(number_repeats)])\n",
    "    return observations.mean()\n",
    "\n",
    "frequencies = []\n",
    "for i in range(1, 1000):\n",
    "    frequencies.append(repeat_game(i))\n",
    "\n",
    "plt.plot(list(range(1, 1000)), frequencies)\n",
    "plt.axhline(0.5, color='k')\n",
    "plt.xlabel('Number of Card Shuffles')\n",
    "plt.ylabel('Win-Frequency')\n",
    "plt.show()\n",
    "print(f\"The win-frequency for 10,000 shuffles is {frequencies[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our strategy fluctuates above and below 50% through-out the entire sampling process. We'll need to compute a confidence interval to ensure that its win-rate is above 50%. We’ll compute the confidence interval by sampling 10,000 card-shuffles 300 times. Shuffling an array is a computationally expensive procedure. **The code below will take approximately 40 seconds to run. Hence, it has been commented out.**\n",
    "\n",
    "**Listing 4. 9. Computing the confidence interval for 3 million shuffles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "np.random.seed(0)\n",
    "frequency_array = np.array([repeat_game(10000) for _ in range(300)])\n",
    "\n",
    "likelihoods, bin_edges, patches = plt.hist(frequency_array, bins='auto',\n",
    "                                           edgecolor='black', density=True)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "start_index, end_index = compute_high_confidence_interval(likelihoods, bin_width)\n",
    "\n",
    "for i in range(start_index, end_index):\n",
    "     patches[i].set_facecolor('yellow')\n",
    "plt.xlabel('Binned Frequency')\n",
    "plt.ylabel('Relative Likelihood')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can narrow the confidence interval by increasing the sample size, at the expense of running time. The code below will sample 50,000 shuffles over 3,000 iterations. **The code will take approximately one hour to run. Hence, it has been commented out.**\n",
    "\n",
    "**Listing 4. 10. Computing the confidence interval for 150 million shuffles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "np.random.seed(0)\n",
    "\n",
    "frequency_array = np.array([repeat_game(50000) for _ in range(3000)])\n",
    "likelihoods, bin_edges = np.histogram(frequency_array, bins='auto',\n",
    "                                      density=True)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "compute_high_confidence_interval(likelihoods, bin_width)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also `min_red_fraction` from 0.5 to 0.75 and repeat the confidence interval calculation process. **As before, the code will take approximately one hour to run. Hence, it has been commented out.**\n",
    "\n",
    "**Listing 4. 11. Computing the confidence interval for an updated strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "np.random.seed(0)\n",
    "def repeat_game(number_repeats, min_red_fraction):\n",
    "    observations = np.array([execute_strategy(min_red_fraction)\n",
    "                            for _ in range(number_repeats)])\n",
    "    return observations.mean()\n",
    "\n",
    "frequency_array = np.array([repeat_game(50000, 0.75) for _ in range(3000)])\n",
    "likelihoods, bin_edges = np.histogram(frequency_array, bins='auto',\n",
    "                                      density=True)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "compute_high_confidence_interval(likelihoods, bin_width)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Optimizing Strategies using the Sample Space for a 10-Card Deck\n",
    "The code below computes the sample space for a 10-card deck. Afterwards, it applies our\n",
    "basic strategy to that sample space. Its output is the probability of a win.\n",
    "\n",
    "**Listing 4. 12. Applying a basic strategy to a 10-card deck**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cards = 10\n",
    "total_red_cards = int(total_cards / 2)\n",
    "total_black_cards = total_red_cards\n",
    "unshuffled_deck = [1] * total_red_cards + [0] * total_black_cards\n",
    "sample_space = set(itertools.permutations(unshuffled_deck))\n",
    "win_condition = lambda x: execute_strategy(shuffled_deck=np.array(x)) \n",
    "prob_win = compute_event_probability(win_condition, sample_space)\n",
    "print(f\"Probability of a win is {prob_win}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, our basic strategy yields a win only 50% of the time. Lets compute the win-probabilities over a range\n",
    "of min_red_fraction values.\n",
    "\n",
    "**Listing 4. 13. Applying multiple strategies to a 10-card deck**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_strategies():\n",
    "    fractions = [value / 100 for value in range(50, 100)]\n",
    "    probabilities = []\n",
    "    for frac in fractions:\n",
    "        win_condition = lambda x: execute_strategy(frac,\n",
    "                                                   shuffled_deck=np.array(x))\n",
    "        probabilities.append(compute_event_probability(win_condition,\n",
    "                                                       sample_space))\n",
    "    return probabilities\n",
    "\n",
    "probabilities = scan_strategies()\n",
    "print(f\"Lowest probability of win is {min(probabilities)}\")\n",
    "print(f\"Highest probability of win is {max(probabilities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the lowest and highest probabilities are equal to 0.5! Perhaps adjusting the deck size will yield some\n",
    "improvement. Let’s analyze the sample spaces of decks containing 2, 4, 6, and 8 cards.\n",
    "\n",
    "**Listing 4. 14. Applying multiple strategies to multiple decks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for total_cards in [2, 4, 6, 8]:\n",
    "    total_red_cards = int(total_cards / 2)\n",
    "    total_black_cards = total_red_cards\n",
    "    unshuffled_deck = [1] * total_red_cards + [0] * total_black_cards\n",
    "\n",
    "    sample_space = set(itertools.permutations(unshuffled_deck))\n",
    "    probabilities = scan_strategies()\n",
    "    if all(prob == 0.5 for prob in probabilities):\n",
    "        print(f\"No winning strategy found for deck of size {total_cards}\")\n",
    "    else:\n",
    "        print(f\"Winning strategy found for deck of size {total_cards}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the strategies yield a probability of 0.5 across the small decks. Our strategies don’t work on a 10-card deck, and we have little reason to believe that they will work on a 52-card deck. To better understand why this is the case, we can re-run our simulations over a 52 card deck while plotting wins and losses relative to halting and non-halting scenarios.\n",
    "\n",
    "**Listing 4. 15. Plotting strategy outcomes across a 52-card deck**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "total_cards = 52\n",
    "total_red_cards = 26\n",
    "unshuffled_deck = red_cards + black_cards\n",
    "\n",
    "def repeat_game_detailed(number_repeats, min_red_fraction):\n",
    "\n",
    "    observations = [execute_strategy(min_red_fraction, return_index=True)\n",
    "                    for _ in range(num_repeats)] \n",
    "    successes = [index for index, card, in observations if card == 1] \n",
    "    halt_success = len([index for index in successes if index != 51]) \n",
    "    no_halt_success = len(successes) - halt_success \n",
    "\n",
    "    failures = [index for index, card, in observations if card == 0] \n",
    "    halt_failure = len([index for index in failures if index != 51]) \n",
    "    no_halt_failure = len(failures) - halt_failure \n",
    "    result = [halt_success, halt_failure, no_halt_success, no_halt_failure]\n",
    "    return [r / number_repeats for r in result] \n",
    "\n",
    "fractions = [value / 100 for value in range(50, 100)]\n",
    "num_repeats = 50000\n",
    "result_types = [[], [], [], []]\n",
    "\n",
    "for fraction in fractions: \n",
    "    result = repeat_game_detailed(num_repeats, fraction)\n",
    "    for i in range(4):\n",
    "        result_types[i].append(result[i])\n",
    "\n",
    "plt.plot(fractions, result_types[0],\n",
    "         label='A) Strategy Halts. We Win.')\n",
    "plt.plot(fractions, result_types[1], linestyle='--',\n",
    "         label='B) Strategy Halts. We Lose.')\n",
    "plt.plot(fractions, result_types[2], linestyle=':',\n",
    "         label='C) No Halt. We Win.')\n",
    "plt.plot(fractions, result_types[3], linestyle='-.',\n",
    "         label='D) No Halt. We Lose.')\n",
    "plt.xlabel('min_red_fraction')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(bbox_to_anchor=(0.25, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The added frequencies of Scenarios A and B appear to fluctuate at around 0.5. No matter what we do, our likelihood of winning remains 50-50. Therefore, the most optimal strategy we can offer is to pick the first card in the shuffled deck.\n",
    "\n",
    "**Listing 4. 16. The most optimal winning strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_strategy(shuffled_deck):\n",
    "    return shuffled_deck[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
